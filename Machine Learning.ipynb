{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season_Epi_code</th>\n",
       "      <th>Pitched_Business_Identifier</th>\n",
       "      <th>Pitched_Business_Desc</th>\n",
       "      <th>Deal_Status</th>\n",
       "      <th>Deal_Shark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Ava the Elephant</td>\n",
       "      <td>(Emmy the Elephant during show, trademarked a...</td>\n",
       "      <td>1</td>\n",
       "      <td>BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>College Foxes Packing Boxes</td>\n",
       "      <td>a packing and organizing service based on an a...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>Ionic Ear</td>\n",
       "      <td>an implantable Bluetooth device requiring surg...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>Mr. Tod's Pie Factory</td>\n",
       "      <td>a pie company</td>\n",
       "      <td>1</td>\n",
       "      <td>BC+DJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>Wispots</td>\n",
       "      <td>an electronic hand-held device for waiting roo...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season_Epi_code  Pitched_Business_Identifier  \\\n",
       "0              101             Ava the Elephant   \n",
       "1              101  College Foxes Packing Boxes   \n",
       "2              101                    Ionic Ear   \n",
       "3              101        Mr. Tod's Pie Factory   \n",
       "4              101                      Wispots   \n",
       "\n",
       "                               Pitched_Business_Desc  Deal_Status Deal_Shark  \n",
       "0   (Emmy the Elephant during show, trademarked a...            1         BC  \n",
       "1  a packing and organizing service based on an a...            0        NaN  \n",
       "2  an implantable Bluetooth device requiring surg...            0        NaN  \n",
       "3                                     a pie company             1      BC+DJ  \n",
       "4  an electronic hand-held device for waiting roo...            0        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitch_file = 'shark_tank_pitch_detail.csv'\n",
    "\n",
    "load2 = pd.read_csv(pitch_file)\n",
    "load2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(corpus):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", corpus) \n",
    "    words = letters_only.lower().split()                            \n",
    "    return( \" \".join( words ))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "addedwords = ('use','line','allow','make','offer','provide','products','design','made','similar','like','play','creates','created','unique')\n",
    "\n",
    "stop = stopwords.words('english')+list(addedwords)\n",
    "\n",
    "load2['Pitched_Business_Desc'] = load2['Pitched_Business_Desc'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emmy elephant show trademarked ava after plastic elephant shaped device helps parents give small children oral medicine emmy elephant show trademarked ava after plastic elephant shaped device lets parents easily give small children oral medicine\n",
      "packing organizing service based already successful business called college hunks hauling junk spinoff professional packing organizing service based already successful junk removal moving business called college hunks hauling junk\n",
      "implantable bluetooth device requiring surgery insert device user s head implantable bluetooth device requiring surgery head\n",
      "pie company\n",
      "electronic hand held device waiting rooms electronic hand held device waiting rooms\n"
     ]
    }
   ],
   "source": [
    "load2['Pitched_Business_Desc'] = load2['Pitched_Business_Desc'].apply(lambda x:data_cleaning(x))\n",
    "load2 = load2[['Deal_Status','Pitched_Business_Desc']]\n",
    "for i in range(5):\n",
    "    print(load2['Pitched_Business_Desc'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(load2,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = []\n",
    "test_corpus = []\n",
    "for each in train['Pitched_Business_Desc']:\n",
    "    train_corpus.append(each)\n",
    "for each in test['Pitched_Business_Desc']:\n",
    "    test_corpus.append(each)\n",
    "## Start creating them\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer(ngram_range=(2,2))\n",
    "train_features = v.fit_transform(train_corpus)\n",
    "test_features=v.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(529, 7790)\n",
      "(177, 7790)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ML models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression # Regression classifier\n",
    "from sklearn.tree import DecisionTreeClassifier # Decision Tree classifier\n",
    "from sklearn import svm # Support Vector Machine\n",
    "from sklearn.linear_model import SGDClassifier # Stochastic Gradient Descent Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier # Random Forest and Gradient Boosting Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes Classifier \n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix # Some metrics to check the performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are tunable to achieve max accuracy\n",
    "\n",
    "\n",
    "Classifiers = {'LR':LogisticRegression(random_state=42,C=5,max_iter=200),\n",
    "               'DTC':DecisionTreeClassifier(random_state=42,min_samples_leaf=2),\n",
    "               'RF':RandomForestClassifier(random_state=42,n_estimators=100,n_jobs=-1),\n",
    "               'GBC':GradientBoostingClassifier(random_state=42,n_estimators=400,learning_rate=0.35),\n",
    "               'SGD':SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
    "               'SVM':svm.SVC(kernel='linear', C=0.10),\n",
    "               'NB':MultinomialNB(alpha=.05)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline to reuse the code\n",
    "def ML_Pipeline(clf_name):\n",
    "    clf = Classifiers[clf_name]\n",
    "    fit = clf.fit(train_features,train['Deal_Status'])\n",
    "    pred = clf.predict(test_features)\n",
    "    Accuracy = accuracy_score(test['Deal_Status'],pred)\n",
    "    Confusion_matrix = confusion_matrix(test['Deal_Status'],pred)\n",
    "    print('==='*20)\n",
    "    print('Accuracy = '+str(Accuracy))\n",
    "    print('==='*20) \n",
    "    print(Confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # ML Code in Individual Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Accuracy = 0.5480225988700564\n",
      "============================================================\n",
      "[[15 58]\n",
      " [22 82]]\n"
     ]
    }
   ],
   "source": [
    "ML_Pipeline('LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Accuracy = 0.5649717514124294\n",
      "============================================================\n",
      "[[ 7 66]\n",
      " [11 93]]\n"
     ]
    }
   ],
   "source": [
    "ML_Pipeline('DTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Accuracy = 0.5875706214689266\n",
      "============================================================\n",
      "[[  0  73]\n",
      " [  0 104]]\n"
     ]
    }
   ],
   "source": [
    "ML_Pipeline('RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Accuracy = 0.5875706214689266\n",
      "============================================================\n",
      "[[  2  71]\n",
      " [  2 102]]\n"
     ]
    }
   ],
   "source": [
    "ML_Pipeline('GBC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Accuracy = 0.5310734463276836\n",
      "============================================================\n",
      "[[12 61]\n",
      " [22 82]]\n"
     ]
    }
   ],
   "source": [
    "ML_Pipeline('NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Accuracy = 0.480225988700565\n",
      "============================================================\n",
      "[[61 12]\n",
      " [80 24]]\n"
     ]
    }
   ],
   "source": [
    "ML_Pipeline('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Accuracy = 0.5536723163841808\n",
      "============================================================\n",
      "[[11 62]\n",
      " [17 87]]\n"
     ]
    }
   ],
   "source": [
    "ML_Pipeline('SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
